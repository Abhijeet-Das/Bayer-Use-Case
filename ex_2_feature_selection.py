# -*- coding: utf-8 -*-
"""Ex 2 Feature Selection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AlUQADE5OKgyrEkw1k71HygIUN88t9H8
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


import seaborn as sns

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
import random
random.seed(42)
p = 0.10  # 10% of the lines
# keep the header, then take only 1% of lines
# if random from [0,1] interval is greater than 0.01 the row will be skipped
df = pd.read_csv(
         '/content/gdrive/My Drive/Colab Notebooks/Bayer/PacakgingLineDataSet.csv', encoding = 'unicode_escape',
         header=0, 
         skiprows=lambda i: i>0 and random.random() > p
)

# Get the shape and head of the data
print(df.shape)
df.head()

# Iterating the columns
for col in df.columns:
    print(col)

# Get the value count of the Class label
df['ProductionYN'].value_counts()

# Plot the Class label distribution
import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
labels = ['0', '1']
vals = [54764, 21196]
ax.bar(labels,vals)
plt.show()

# We have 667 PLC tags. So we would like to perform supervised feature selection of PLC Tags wrt Class label ProductionYN. 
# First we will create a dataframe of PLC Tags and class label and check if all the PLC Tags are numeric and deal with the non-numeric

# Create a dataframe of PLC Tags
N = 666
# Select last N columns of dataframe
currDf = df.iloc[: , -N:]
currDf = currDf.iloc[: , :-1] # Remove the last date column

currDf['ProductionYN'] = df['ProductionYN']

currDf.head()

# Checking if the currDf dataframe with PLC Tags have some non-numeric entities
stringType = []
for x in range(0, 666):
  if(currDf.iloc[:, x].dtype == 'object'):
    stringType.append(x)
print(stringType)  

for x in range(0, len(stringType)):
   print(currDf.iloc[:, stringType[x]].unique())

# Only the stringType = [608, 616, 617,  644] seems to have discreate values, so we will consider only these non-numeric columns
# We will first drop the unwanted cols and then use Label Encoder. We need to do a train-test split of the currDf before Label Encoder

# Remove cols 629, 631, 633, 636, 639, 640, 642
currDf.drop(currDf.columns[[629, 631, 633, 636, 639, 640, 642]], axis = 1, inplace = True)

print(currDf.shape)
currDf.head()

# Checking if the currDf dataframe with PLC Tags have some non-numeric entities
stringType = []
for x in range(0, 659):
  if(currDf.iloc[:, x].dtype == 'object'):
    stringType.append(x)
print(stringType)  

for x in range(0, len(stringType)):
   print(currDf.iloc[:, stringType[x]].unique())

print(currDf.shape)
from sklearn.model_selection import train_test_split

train, test = train_test_split(currDf, test_size=0.25, random_state= 42)

print(train.shape)
print(test.shape)

from sklearn.preprocessing import LabelEncoder
for x in range(0, len(stringType)):
  print(stringType[x])
  le = LabelEncoder()
  train.iloc[:, stringType[x]] = le.fit_transform(train.iloc[:,stringType[x]].astype(str)) 
  test.iloc[:, stringType[x]] = le.transform(test.iloc[:,stringType[x]].astype(str))

# Before applying ML algorithms to determine Feature Selection, it is better to do standardization of the features. Let us use a few Feature Selection algo

# Feature Selection using correlation analysis
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train)
train_scaled = pd.DataFrame(train_scaled)
test_scaled = scaler.transform(test)
test_scaled = pd.DataFrame(test_scaled)

cor = train_scaled.corr()
cor_target = abs(cor.iloc[:, 658])  
relevant_features = cor_target[cor_target > 0.5]
relevant_features.index

# checking the relevancy of these Features using Decision Tree Classifier

print(len(relevant_features))
# Last label is the class label itself

X_train = train_scaled.iloc[:, relevant_features.index[:-1]]
y_train=  train_scaled.iloc[:, 658]

X_test = test_scaled.iloc[:, relevant_features.index[:-1]]
y_test=  test_scaled.iloc[:, 658]

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.metrics import roc_curve, roc_auc_score, f1_score

clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_train,y_train)
y_predict = clf_model.predict(X_test)


print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

# Using random Oversampling to make class labels equal 

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_res, y_res = ros.fit_resample(X_train, y_train)

clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_res,y_res)

y_predict = clf_model.predict(X_test)

print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

from pandas.core.common import random_state
from imblearn.combine import SMOTETomek
from imblearn.under_sampling import TomekLinks
#from imblearn.over_sampling import SMOTE
#from imblearn.under_sampling import TomekLinks 

#tl = TomekLinks()
#sm = SMOTE(random_state=42)
smteok = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'), random_state=42)

X_res, y_res = smteok.fit_resample(X_train, y_train)
clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_res,y_res)

y_predict = clf_model.predict(X_test)

print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

# The Smote Tomek Sampling method gives better results. So Lets check a few other Feature Selection and evaluate using Decision Tree and Smote Tomek way of Sampling

# Select K best Feature Selection Algo and lets take top 70 features

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train)
train_scaled = pd.DataFrame(train_scaled)
test_scaled = scaler.transform(test)
test_scaled = pd.DataFrame(test_scaled)

N = 658
X_train = train_scaled.iloc[:, :N]
y_train=  train_scaled.iloc[:, 658]

X_test = test_scaled.iloc[:, :N]
y_test=  test_scaled.iloc[:, 658]

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

select = SelectKBest(score_func=f_classif, k=69)
z = select.fit_transform(X_train,y_train)
 
print("After selecting best 3 features:", z.shape)

thisFeat = X_train.columns[select.get_support(indices=True)].tolist()
thisFeat

X_train = X_train.iloc[:, thisFeat]
X_test = X_test.iloc[:, thisFeat]


print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.metrics import roc_curve, roc_auc_score, f1_score

clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_train,y_train)
y_predict = clf_model.predict(X_test)


print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

# Using random Oversampling to make class labels equal 

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_res, y_res = ros.fit_resample(X_train, y_train)

clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_res,y_res)

y_predict = clf_model.predict(X_test)

print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

from pandas.core.common import random_state
from imblearn.combine import SMOTETomek
from imblearn.under_sampling import TomekLinks
#from imblearn.over_sampling import SMOTE
#from imblearn.under_sampling import TomekLinks 

#tl = TomekLinks()
#sm = SMOTE(random_state=42)
smteok = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'), random_state=42)

X_res, y_res = smteok.fit_resample(X_train, y_train)
clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_res,y_res)

y_predict = clf_model.predict(X_test)

print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

# Extra Trees Classifier

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train)
train_scaled = pd.DataFrame(train_scaled)
test_scaled = scaler.transform(test)
test_scaled = pd.DataFrame(test_scaled)

N = 658
X_train = train_scaled.iloc[:, :N]
y_train=  train_scaled.iloc[:, 658]

X_test = test_scaled.iloc[:, :N]
y_test=  test_scaled.iloc[:, 658]

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.ensemble import ExtraTreesClassifier
model = ExtraTreesClassifier()
model.fit(X_train, y_train)
print(model.feature_importances_)
feat_importances = pd.Series(model.feature_importances_, index= X_train.columns)

thisFeat = (feat_importances.nlargest(69).index)

thisFeat

X_train = X_train.iloc[:, thisFeat]
X_test = X_test.iloc[:, thisFeat]


print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.metrics import roc_curve, roc_auc_score, f1_score

clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_train,y_train)
y_predict = clf_model.predict(X_test)


print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

# Using random Oversampling to make class labels equal 

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_res, y_res = ros.fit_resample(X_train, y_train)

clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_res,y_res)

y_predict = clf_model.predict(X_test)

print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

from pandas.core.common import random_state
from imblearn.combine import SMOTETomek
from imblearn.under_sampling import TomekLinks
#from imblearn.over_sampling import SMOTE
#from imblearn.under_sampling import TomekLinks 

#tl = TomekLinks()
#sm = SMOTE(random_state=42)
smteok = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'), random_state=42)

X_res, y_res = smteok.fit_resample(X_train, y_train)
clf_model = DecisionTreeClassifier(criterion="gini", random_state=42)   
clf_model.fit(X_res,y_res)

y_predict = clf_model.predict(X_test)

print(accuracy_score(y_test,y_predict))
print(roc_auc_score(y_test,y_predict))
print(f1_score(y_test,y_predict))

# We find the Feature Selection Subset having highest F1 score 
thisFeat

N = 658
X_train_name = train.iloc[:, :N]

X_train_name = X_train_name.iloc[:, thisFeat]
X_train_name.head()

selFeat = X_train_name.columns.values.tolist()
selFeat

# Understanding Causlity with the help of Partial Correlation

from scipy import stats, linalg
def partial_corr(C):
    """
    Returns the sample linear partial correlation coefficients between pairs of variables in C, controlling 
    for the remaining variables in C.
    Parameters
    ----------
    C : array-like, shape (n, p)
        Array with the different variables. Each column of C is taken as a variable
    Returns
    -------
    P : array-like, shape (p, p)
        P[i, j] contains the partial correlation of C[:, i] and C[:, j] controlling
        for the remaining variables in C.
    """

    C = np.asarray(C)
    p = C.shape[1]
    P_corr = np.zeros((p, p), dtype=np.float)
    for i in range(p):
        P_corr[i, i] = 1
        for j in range(i+1, p):
            idx = np.ones(p, dtype=np.bool)
            idx[i] = False
            idx[j] = False
            beta_i = linalg.lstsq(C[:, idx], C[:, j])[0]
            beta_j = linalg.lstsq(C[:, idx], C[:, i])[0]

            res_j = C[:, j] - C[:, idx].dot( beta_i)
            res_i = C[:, i] - C[:, idx].dot(beta_j)

            corr = stats.pearsonr(res_i, res_j)[0]
            P_corr[i, j] = corr
            P_corr[j, i] = corr

    return P_corr

# The Correlation between some of the columns
X_train.iloc[:, [1,4,5,6,9]].corr()

partial_corr_array = (X_train.iloc[:, [1,4,5,6,9]].values)


# Calculate the partial correlation coefficients
partial_corr(partial_corr_array)

X_train.iloc[:, [1,5,6]].corr()

partial_corr_array = (X_train.iloc[:, [1,5,6]].values)


# Calculate the partial correlation coefficients
partial_corr(partial_corr_array)

X_train.iloc[:, [1,2,3]].corr()

partial_corr_array = (X_train.iloc[:, [1,2,3]].values)


# Calculate the partial correlation coefficients
partial_corr(partial_corr_array)